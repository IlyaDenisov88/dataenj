{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOnhpogbkcF0fUKf2yDPsFB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaDenisov88/dataenj/blob/main/PySpark/Repartition_and_Coalesce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhgS_-g7P0gQ",
        "outputId": "834b40fd-4b6d-4c78-b34a-f14149758a10"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=af6aec987a7d445f770cd7e152aa7a116dd9faf182970eb6bb0f57b013d13eea\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Для чего нужен repartition?\n",
        "\n",
        "* **Балансировка нагрузки:** Когда данные распределены неравномерно по разделам, некоторые задачи могут занять больше времени на выполнение. repartition помогает перераспределить данные более равномерно.\n",
        "* **Оптимизация выполнения:** Некоторые операции, такие как join и groupBy, могут быть более эффективными, если данные предварительно перераспределены.\n",
        "* **Увеличение или уменьшение количества разделов:** repartition позволяет изменять количество разделов для более эффективного использования ресурсов кластера.\n",
        "\n",
        "Рассмотрим пример, где мы создаем DataFrame, применяем repartition, и видим, как изменяется количество разделов."
      ],
      "metadata": {
        "id": "PKukhBerFPjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhgSWZXdDh0o",
        "outputId": "b6823337-e5bf-4965-c634-ae14a9d1cd04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of partitions: 2\n",
            "New number of partitions: 15\n",
            "Number of partitions after join: 200\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Создаем SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Repartition Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Пример данных\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(100)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Проверяем начальное количество разделов\n",
        "initial_partitions = df.rdd.getNumPartitions()\n",
        "print(f\"Initial number of partitions: {initial_partitions}\")\n",
        "\n",
        "# Применяем repartition для увеличения количества разделов до 15\n",
        "df_repartitioned = df.repartition(15)\n",
        "\n",
        "# Проверяем новое количество разделов\n",
        "new_partitions = df_repartitioned.rdd.getNumPartitions()\n",
        "print(f\"New number of partitions: {new_partitions}\")\n",
        "\n",
        "# Пример использования для улучшения выполнения join\n",
        "other_data = [(i, f\"OtherName_{i % 5}\") for i in range(100)]\n",
        "other_df = spark.createDataFrame(other_data, [\"id\", \"other_name\"])\n",
        "\n",
        "# Применяем repartition перед join\n",
        "df_repartitioned = df.repartition(10, \"id\")\n",
        "joined_df = df_repartitioned.join(other_df, \"id\")\n",
        "\n",
        "# Проверяем количество разделов после join\n",
        "joined_partitions = joined_df.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions after join: {joined_partitions}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Создаем объект SparkSession.\n",
        "2. Создаем DataFrame из примера данных.\n",
        "3. Используем getNumPartitions, чтобы узнать количество разделов в исходном DataFrame.\n",
        "4. Увеличиваем количество разделов до 15.\n",
        "5. Проверяем количество разделов после применения repartition.\n",
        "6. Создаем другой DataFrame и применяем repartition по столбцу id перед выполнением join операции. Это помогает улучшить производительность join, так как данные будут предварительно распределены.\n",
        "7. Проверяем количество разделов в результирующем DataFrame после join.\n",
        "8. Останавливаем SparkSession."
      ],
      "metadata": {
        "id": "quqhemdkGCmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если читаем с CSV какого - нибудь, то также можно указать, сколько партиций должно быть"
      ],
      "metadata": {
        "id": "ovwHzym1QkUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Чтение CSV-файла\n",
        "df = spark.read.csv(\"/content/sample_data/mnist_test.csv\", header=True, inferSchema=True)\n",
        "\n",
        "# Установка количества разделов (партиций)\n",
        "df = df.repartition(10)\n",
        "\n",
        "# Проверка количества разделов\n",
        "print(f\"Number of partitions: {df.rdd.getNumPartitions()}\")\n",
        "\n",
        "# Останавливаем SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DC2omw8GGMvM",
        "outputId": "17e6a822-3b8b-4b34-a0a9-c9b8fe1343b4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of partitions: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shuffle"
      ],
      "metadata": {
        "id": "FvnPI16pP-fB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Партиции в процессе shuffle играют ключевую роль в распределении данных по узлам кластера. Каждая операция shuffle создает новые партиции, и количество этих партиций может быть настроено для оптимизации производительности.\n",
        "\n",
        "Рассмотрим пример, где мы создаем DataFrame, выполняем операцию join, которая требует shuffle, и настроим количество партиций для операции shuffle."
      ],
      "metadata": {
        "id": "5Mh4AAa-P5Wu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Создаем SparkSession и настраиваем количество партиций для shuffle\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Shuffle Example\") \\\n",
        "    .config(\"spark.sql.shuffle.partitions\", \"50\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Проверяем текущую настройку количества партиций для shuffle\n",
        "print(f\"Current shuffle partitions setting: {spark.conf.get('spark.sql.shuffle.partitions')}\")\n",
        "\n",
        "# Пример данных с большим объемом\n",
        "data1 = [(i, f\"Name_{i % 5}\") for i in range(1000000)]\n",
        "data2 = [(i, f\"Category_{i % 3}\") for i in range(1000000)]\n",
        "\n",
        "df1 = spark.createDataFrame(data1, [\"id\", \"name\"])\n",
        "df2 = spark.createDataFrame(data2, [\"id\", \"category\"])\n",
        "\n",
        "# Проверяем начальное количество партиций\n",
        "initial_partitions_df1 = df1.rdd.getNumPartitions()\n",
        "initial_partitions_df2 = df2.rdd.getNumPartitions()\n",
        "print(f\"Initial number of partitions in df1: {initial_partitions_df1}\")\n",
        "print(f\"Initial number of partitions in df2: {initial_partitions_df2}\")\n",
        "\n",
        "# Принудительно увеличиваем количество партиций перед join\n",
        "df1_repartitioned = df1.repartition(100)\n",
        "df2_repartitioned = df2.repartition(100)\n",
        "\n",
        "# Проверяем количество партиций после repartition\n",
        "repartitioned_partitions_df1 = df1_repartitioned.rdd.getNumPartitions()\n",
        "repartitioned_partitions_df2 = df2_repartitioned.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions in df1 after repartition: {repartitioned_partitions_df1}\")\n",
        "print(f\"Number of partitions in df2 after repartition: {repartitioned_partitions_df2}\")\n",
        "\n",
        "# Выполняем операцию join, требующую shuffle\n",
        "joined_df = df1_repartitioned.join(df2_repartitioned, \"id\")\n",
        "\n",
        "# Проверяем количество партиций после join\n",
        "joined_partitions = joined_df.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions after join: {joined_partitions}\")\n",
        "\n",
        "# Останавливаем SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "UGPvUDsLPuSy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f81c31-ac6e-4748-a46d-c599c9c3f67b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current shuffle partitions setting: 50\n",
            "Initial number of partitions in df1: 2\n",
            "Initial number of partitions in df2: 2\n",
            "Number of partitions in df1 after repartition: 100\n",
            "Number of partitions in df2 after repartition: 100\n",
            "Number of partitions after join: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметр `spark.sql.shuffle.partitions` позволяет настроить количество партиций для операций shuffle. По умолчанию это значение равно 200, но его можно изменить в зависимости от объема данных и конфигурации кластера."
      ],
      "metadata": {
        "id": "gPGe8q01RDFn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Coalesce"
      ],
      "metadata": {
        "id": "c3WN2uPUg7mo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "coalesce оптимизирована для уменьшения количества партиций без shuffle, если это возможно."
      ],
      "metadata": {
        "id": "y7h0vB0IhHY2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Опа! То есть repartition всегда нужно использовать, если мы перераспределяем данные - запомнили.\n",
        "\n",
        "То есть coalesce нужен для уменьшения количества партиций, чтобы избежать избыточного количества мелких партиций, что может улучшить производительность при выполнении некоторых операций. Приведем пример -"
      ],
      "metadata": {
        "id": "GJ_PYdxBhBOj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "# Создаем SparkSession\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Coalesce Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "# Пример данных\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(100)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Проверяем начальное количество партиций\n",
        "initial_partitions = df.rdd.getNumPartitions()\n",
        "print(f\"Initial number of partitions: {initial_partitions}\")\n",
        "\n",
        "# Применяем repartition для увеличения количества партиций до 10 (для демонстрации)\n",
        "df_repartitioned = df.repartition(10)\n",
        "repartitioned_partitions = df_repartitioned.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions after repartition: {repartitioned_partitions}\")\n",
        "\n",
        "# Применяем coalesce для уменьшения количества партиций до 3\n",
        "df_coalesced = df_repartitioned.coalesce(3)\n",
        "coalesced_partitions = df_coalesced.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions after coalesce: {coalesced_partitions}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOXyI3DfhAow",
        "outputId": "83a83418-a718-43ac-ce29-5443a255b9b7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial number of partitions: 2\n",
            "Number of partitions after repartition: 10\n",
            "Number of partitions after coalesce: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Создаем объект SparkSession.\n",
        "* Создаем DataFrame из примера данных.\n",
        "* Используем getNumPartitions, чтобы узнать количество партиций в исходном DataFrame.\n",
        "* Увеличиваем количество партиций до 10 для демонстрации.\n",
        "* Уменьшаем количество партиций до 3 без shuffle.\n",
        "* Проверяем количество партиций после применения coalesce."
      ],
      "metadata": {
        "id": "Dk3skzKohUKC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Все вроде понятно... Но, а что если все таки нужно уменьшить количество партиций с shuffle, как быть? Просто добавьте флаг True, как в примере ниже. Но! Я очень не советую уменьшать партиции в моменте, лучше перезагрузить файл с нужным количество партиций, если это возможно, чем потом пытаться делить неделимое.\n",
        "\n"
      ],
      "metadata": {
        "id": "fyEUvWwlhaYB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# в новых версиях PySpark так не работает, можно сделать сначала repartition, потом coalesce\n",
        "df_coalesced_with_shuffle = df_repartitioned.coalesce(3, shuffle=True)\n",
        "coalesced_partitions_with_shuffle = df_coalesced_with_shuffle.rdd.getNumPartitions()\n",
        "print(f\"Number of partitions after coalesce with shuffle: {coalesced_partitions_with_shuffle}\")\n",
        "# Останавливаем SparkSession\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "FM8jxZ4Khcy9",
        "outputId": "c51c72c7-cd2c-452e-ecab-5d6c02418af7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "DataFrame.coalesce() got an unexpected keyword argument 'shuffle'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-2e304b57a730>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_coalesced_with_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_repartitioned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoalesce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcoalesced_partitions_with_shuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_coalesced_with_shuffle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrdd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetNumPartitions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of partitions after coalesce with shuffle: {coalesced_partitions_with_shuffle}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Останавливаем SparkSession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: DataFrame.coalesce() got an unexpected keyword argument 'shuffle'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Разница repartition() и partitionBy()"
      ],
      "metadata": {
        "id": "8r-RVXFviiSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`partitionBy` - это метод, используемый при записи данных в файлы (например, в форматах Parquet, ORC, etc.) для указания того, как данные должны быть разделены на партиции. Он определяет логику разделения данных на основе значений одного или нескольких столбцов. И, как всегда пример -\n",
        "\n"
      ],
      "metadata": {
        "id": "2puuc7TNiu9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "spark = SparkSession.builder.appName(\"PartitionBy Example\").getOrCreate()\n",
        "\n",
        "\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(100)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Запись DataFrame с использованием partitionBy по столбцу \"name\".\n",
        "df.write.partitionBy(\"name\").parquet(\"output/path/\")\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "l57Ycj6eiucy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "В данном примере данные будут разделены по столбцу \"name\", и каждый уникальный `name` будет сохранен в отдельной папке. Думаю, разницу Вы уже видите. Но, давайте все таки ее запишем.\n",
        "\n",
        "* repartition : Изменяет количество партиций для распределения вычислительной нагрузки.\n",
        "* partitionBy: Определяет, как данные должны быть разделены на партиции при записи на диск.\n",
        "* repartition используется в контексте изменения числа партиций в DataFrame или RDD для улучшения производительности вычислений.\n",
        "* partitionBy используется в контексте записи данных в файлы, чтобы структурировать данные по определенным столбцам.\n",
        "\n",
        "То есть грубо говоря один используется перед началом работы с файлами, а другой уже делит файлы на части после работы с ними.\n",
        "\n"
      ],
      "metadata": {
        "id": "ErsHoFgVi6pn"
      }
    }
  ]
}