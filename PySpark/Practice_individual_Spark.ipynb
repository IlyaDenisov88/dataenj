{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "qxxCWY9xtjZs",
        "gL7lBdP7tmdC"
      ],
      "mount_file_id": "1L_-D38xhJKg83lC7GQeQeGW-0qwJE9v9",
      "authorship_tag": "ABX9TyOIBFUpOkE0Emn1ho2fUhyy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaDenisov88/dataenj/blob/main/PySpark/Practice_individual_Spark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJR1p4wC1wNu",
        "outputId": "f60570a9-5d05-479d-fb92-8525613ec170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=060a04e1c84cf3ee83ab6ac9ffb36ea94c20dc42d1e5377850745a1987c4961f\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ],
      "source": [
        "pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import to_date, to_timestamp, col\n",
        "from datetime import datetime\n",
        "from pyspark.sql.types import DateType"
      ],
      "metadata": {
        "id": "0SEXnQ272bUu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №1. Погода"
      ],
      "metadata": {
        "id": "qxxCWY9xtjZs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        ".appName(\"Weather\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/weather_data.csv\", header=True)\n",
        "print(df.dtypes)\n",
        "df = df.withColumn(\"date\", to_date(col(\"date\"), 'yyyy-MM-dd'))\n",
        "print(df.dtypes)\n",
        "\n",
        "\n",
        "df = df.withColumn(\"temperature\", col(\"temperature\").cast(\"float\"))\n",
        "df = df.withColumn(\"precipitation\", col(\"precipitation\").cast(\"float\"))\n",
        "df = df.withColumn(\"wind_speed\", col(\"wind_speed\").cast(\"float\"))\n",
        "# вот тут как раз видно отложенное выполнение(\"ленивое выполнение\") спарком на практике\n",
        "# тут типы данных не преобразовались, но ниже в sql запросах теперь все корректно\n",
        "\n",
        "\n",
        "\n",
        "print(df.count())\n",
        "df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMKWt13L2gAQ",
        "outputId": "82c04d40-de5b-443b-aa62-178afc402f4f"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('station_id', 'string'), ('date', 'string'), ('temperature', 'string'), ('precipitation', 'string'), ('wind_speed', 'string')]\n",
            "[('station_id', 'string'), ('date', 'date'), ('temperature', 'string'), ('precipitation', 'string'), ('wind_speed', 'string')]\n",
            "1000\n",
            "+----------+----------+-----------+-------------+----------+\n",
            "|station_id|      date|temperature|precipitation|wind_speed|\n",
            "+----------+----------+-----------+-------------+----------+\n",
            "| station_7|2022-06-28|  -6.751842|    23.670044|     5.459|\n",
            "| station_4|2020-04-07|  -9.574844|    2.9858243| 6.8285055|\n",
            "| station_8|2018-12-22|   19.34342|    33.582115|  8.975576|\n",
            "| station_5|2021-09-09|  30.880953|    29.110437| 18.264654|\n",
            "| station_7|2023-02-07|  23.459047|    49.510445| 3.7878683|\n",
            "|station_10|2018-05-07|  27.525618|    11.957939|0.10053105|\n",
            "| station_3|2019-08-27|  4.2879057|    26.536867| 1.2019283|\n",
            "| station_7|2023-04-13|  19.244547|    32.547867| 18.095327|\n",
            "| station_8|2020-10-10|  1.2541745|    32.229557| 12.950329|\n",
            "| station_5|2018-02-20|  11.530277|    28.064676| 5.4608126|\n",
            "| station_4|2021-12-01|    8.89809|      38.8464|   3.54385|\n",
            "| station_8|2022-11-28|  -9.386771|    10.249061|  5.885335|\n",
            "| station_8|2022-06-25|  3.2247257|     36.28136| 2.2959385|\n",
            "| station_3|2022-07-04|  37.829338|    30.986729| 18.830658|\n",
            "| station_6|2021-04-20| -5.0851846|    44.803757| 15.684123|\n",
            "| station_5|2023-01-29| -11.971776|    42.359722|  9.247824|\n",
            "| station_2|2019-07-21|   5.114837|    15.757352| 17.299252|\n",
            "| station_8|2020-07-24|  27.420263|    13.811866|  4.989164|\n",
            "| station_6|2023-04-19|  14.928894|    49.082664| 14.342411|\n",
            "| station_2|2021-08-25|   20.85849|    26.363258|  17.12265|\n",
            "+----------+----------+-----------+-------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in df.columns:\n",
        "  print(df[column].isNull())"
      ],
      "metadata": {
        "id": "RUMxf7R23f28",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "147fbbfe-2437-40f5-b9b0-4d16b1d44baa"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column<'(station_id IS NULL)'>\n",
            "Column<'(date IS NULL)'>\n",
            "Column<'(temperature IS NULL)'>\n",
            "Column<'(precipitation IS NULL)'>\n",
            "Column<'(wind_speed IS NULL)'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# пропущенных значений нет"
      ],
      "metadata": {
        "id": "Jvy175ds2sL-"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Найдите топ-5 самых жарких дней за все время наблюдений.\n",
        "- Найдите метеостанцию с наибольшим количеством осадков за последний год.\n",
        "- Подсчитайте среднюю температуру по месяцам за все время наблюдений.\n",
        "\n"
      ],
      "metadata": {
        "id": "h_KOgo6tnKDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"df\")\n",
        "\n",
        "top_hot = spark.sql(\"\"\"\n",
        "SELECT date, temperature\n",
        "FROM df\n",
        "ORDER BY df.temperature DESC\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "top_hot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUJgkb7ZnH4e",
        "outputId": "d074d875-654c-4a68-fccd-3595d77a7c7b"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+\n",
            "|      date|temperature|\n",
            "+----------+-----------+\n",
            "|2021-08-20|   39.98283|\n",
            "|2023-12-02|  39.967976|\n",
            "|2022-03-28|  39.824688|\n",
            "|2019-02-11|  39.767376|\n",
            "|2020-06-10|   39.69148|\n",
            "+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_precipitation = spark.sql(\"\"\"\n",
        "SELECT station_id, sum(precipitation)\n",
        "FROM df\n",
        "WHERE date > '2023-09-24'\n",
        "GROUP BY station_id\n",
        "ORDER BY sum(precipitation) DESC\n",
        "LIMIT 1;\n",
        "\"\"\")\n",
        "top_precipitation.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDAGb6FInwdn",
        "outputId": "d849abe2-241d-4277-dc1b-8deb6711732f"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+------------------+\n",
            "|station_id|sum(precipitation)|\n",
            "+----------+------------------+\n",
            "| station_5|164.60128784179688|\n",
            "+----------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import year, month, avg"
      ],
      "metadata": {
        "id": "Zo_ZB6hvprAd"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_monthly = df.groupBy(month(\"date\").alias(\"month\")).agg(\n",
        "    avg(\"temperature\").alias(\"average_temperature\"),\n",
        ")\n",
        "df_sorted = df_monthly.orderBy(col(\"average_temperature\").desc()) # использование col помогает во многом\n",
        "\n",
        "df_sorted.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQp6BcdBpAky",
        "outputId": "ec6cceef-e858-4674-d8ff-dbcaaad5317f"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----+-------------------+\n",
            "|month|average_temperature|\n",
            "+-----+-------------------+\n",
            "|    6| 13.421092370936744|\n",
            "|    4| 12.024529053670603|\n",
            "|    1| 11.356518470007797|\n",
            "|   12| 11.218592057529005|\n",
            "|    8| 10.967800280712183|\n",
            "|    5|  9.902883278588726|\n",
            "|    9|  9.596744181906304|\n",
            "|   10|  9.098843419781097|\n",
            "|    2|   9.06722993850708|\n",
            "|   11|  7.265890174138714|\n",
            "|    3|  7.244080115937525|\n",
            "|    7|  6.185718382110021|\n",
            "+-----+-------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "6mV3Te9UnwYq"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №2. Книги и авторы"
      ],
      "metadata": {
        "id": "gL7lBdP7tmdC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType, StringType, DateType, FloatType"
      ],
      "metadata": {
        "id": "TXxvK4LuvJW4"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        ".appName(\"Books\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "books_df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/books.csv\", header=True)\n",
        "authors_df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/authors.csv\", header=True)\n",
        "books_df.show()\n",
        "authors_df.show()\n",
        "print(books_df.dtypes)\n",
        "print(authors_df.dtypes)\n",
        "book_data_types = {\n",
        "    \"book_id\": IntegerType(),\n",
        "    \"title\": StringType(),\n",
        "    \"author_id\": IntegerType(),\n",
        "    \"genre\": StringType(),\n",
        "    \"price\": FloatType(),\n",
        "    \"publish_date\": DateType()\n",
        "}\n",
        "authors_data_types = {\n",
        "    \"author_id\": IntegerType(),\n",
        "    \"name\": StringType(),\n",
        "    \"birth_date\": DateType(),\n",
        "    \"country\": StringType()\n",
        "}\n",
        "for column_name, data_type in book_data_types.items():\n",
        "  books_df = books_df.withColumn(column_name, col(column_name).cast(data_type))\n",
        "for column_name, data_type in authors_data_types.items():\n",
        "  authors_df = authors_df.withColumn(column_name, col(column_name).cast(data_type))\n",
        "\n",
        "print(books_df.dtypes)\n",
        "print(authors_df.dtypes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XOnH4m2dtpsh",
        "outputId": "d29d5c85-1c0e-40ef-adbd-74491320b79c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|book_id|  title|author_id|      genre|price|publish_date|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "|      1| Book_1|        2|    Mystery|73.57|  1980-12-31|\n",
            "|      2| Book_2|        1|Non-Fiction| 41.1|  1982-12-31|\n",
            "|      3| Book_3|       10|    Fiction|10.63|  1984-12-31|\n",
            "|      4| Book_4|        9|Non-Fiction|46.31|  1986-12-31|\n",
            "|      5| Book_5|        7|    Science|31.13|  1988-12-31|\n",
            "|      6| Book_6|        4|Non-Fiction| 83.7|  1990-12-31|\n",
            "|      7| Book_7|        6|Non-Fiction|40.36|  1992-12-31|\n",
            "|      8| Book_8|        2|Non-Fiction|84.48|  1994-12-31|\n",
            "|      9| Book_9|        7|    Fantasy|10.05|  1996-12-31|\n",
            "|     10|Book_10|        2|    Science| 37.7|  1998-12-31|\n",
            "|     11|Book_11|       10|Non-Fiction| 31.7|  2000-12-31|\n",
            "|     12|Book_12|        8|Non-Fiction|31.02|  2002-12-31|\n",
            "|     13|Book_13|        8|Non-Fiction|16.14|  2004-12-31|\n",
            "|     14|Book_14|        1|    Fiction|26.84|  2006-12-31|\n",
            "|     15|Book_15|        8|    Fantasy| 60.0|  2008-12-31|\n",
            "|     16|Book_16|        2|    Fiction|36.22|  2010-12-31|\n",
            "|     17|Book_17|        6|    Fantasy|47.57|  2012-12-31|\n",
            "|     18|Book_18|        1|Non-Fiction|43.92|  2014-12-31|\n",
            "|     19|Book_19|        5|    Science|88.83|  2016-12-31|\n",
            "|     20|Book_20|        7|    Mystery|91.48|  2018-12-31|\n",
            "+-------+-------+---------+-----------+-----+------------+\n",
            "\n",
            "+---------+---------+----------+---------+\n",
            "|author_id|     name|birth_date|  country|\n",
            "+---------+---------+----------+---------+\n",
            "|        1| Author_1|1960-12-31|    India|\n",
            "|        2| Author_2|1965-12-31|   Canada|\n",
            "|        3| Author_3|1970-12-31|      USA|\n",
            "|        4| Author_4|1975-12-31|       UK|\n",
            "|        5| Author_5|1980-12-31|      USA|\n",
            "|        6| Author_6|1985-12-31|      USA|\n",
            "|        7| Author_7|1990-12-31|      USA|\n",
            "|        8| Author_8|1995-12-31|Australia|\n",
            "|        9| Author_9|2000-12-31|Australia|\n",
            "|       10|Author_10|2005-12-31|    India|\n",
            "+---------+---------+----------+---------+\n",
            "\n",
            "[('book_id', 'string'), ('title', 'string'), ('author_id', 'string'), ('genre', 'string'), ('price', 'string'), ('publish_date', 'string')]\n",
            "[('author_id', 'string'), ('name', 'string'), ('birth_date', 'string'), ('country', 'string')]\n",
            "[('book_id', 'int'), ('title', 'string'), ('author_id', 'int'), ('genre', 'string'), ('price', 'float'), ('publish_date', 'date')]\n",
            "[('author_id', 'int'), ('name', 'string'), ('birth_date', 'date'), ('country', 'string')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_join = books_df.join(authors_df, \"author_id\", \"left\")\n",
        "df_join.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ImhdozmTw7u2",
        "outputId": "bd41e82a-9658-4bda-f67d-6d1e183edb7d"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|author_id|book_id|  title|      genre|price|publish_date|     name|birth_date|  country|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|        2|      1| Book_1|    Mystery|73.57|  1980-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        1|      2| Book_2|Non-Fiction| 41.1|  1982-12-31| Author_1|1960-12-31|    India|\n",
            "|       10|      3| Book_3|    Fiction|10.63|  1984-12-31|Author_10|2005-12-31|    India|\n",
            "|        9|      4| Book_4|Non-Fiction|46.31|  1986-12-31| Author_9|2000-12-31|Australia|\n",
            "|        7|      5| Book_5|    Science|31.13|  1988-12-31| Author_7|1990-12-31|      USA|\n",
            "|        4|      6| Book_6|Non-Fiction| 83.7|  1990-12-31| Author_4|1975-12-31|       UK|\n",
            "|        6|      7| Book_7|Non-Fiction|40.36|  1992-12-31| Author_6|1985-12-31|      USA|\n",
            "|        2|      8| Book_8|Non-Fiction|84.48|  1994-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        7|      9| Book_9|    Fantasy|10.05|  1996-12-31| Author_7|1990-12-31|      USA|\n",
            "|        2|     10|Book_10|    Science| 37.7|  1998-12-31| Author_2|1965-12-31|   Canada|\n",
            "|       10|     11|Book_11|Non-Fiction| 31.7|  2000-12-31|Author_10|2005-12-31|    India|\n",
            "|        8|     12|Book_12|Non-Fiction|31.02|  2002-12-31| Author_8|1995-12-31|Australia|\n",
            "|        8|     13|Book_13|Non-Fiction|16.14|  2004-12-31| Author_8|1995-12-31|Australia|\n",
            "|        1|     14|Book_14|    Fiction|26.84|  2006-12-31| Author_1|1960-12-31|    India|\n",
            "|        8|     15|Book_15|    Fantasy| 60.0|  2008-12-31| Author_8|1995-12-31|Australia|\n",
            "|        2|     16|Book_16|    Fiction|36.22|  2010-12-31| Author_2|1965-12-31|   Canada|\n",
            "|        6|     17|Book_17|    Fantasy|47.57|  2012-12-31| Author_6|1985-12-31|      USA|\n",
            "|        1|     18|Book_18|Non-Fiction|43.92|  2014-12-31| Author_1|1960-12-31|    India|\n",
            "|        5|     19|Book_19|    Science|88.83|  2016-12-31| Author_5|1980-12-31|      USA|\n",
            "|        7|     20|Book_20|    Mystery|91.48|  2018-12-31| Author_7|1990-12-31|      USA|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Найдите топ-5 авторов, книги которых принесли наибольшую выручку.\n",
        "- Найдите количество книг в каждом жанре.\n",
        "- Подсчитайте среднюю цену книг по каждому автору.\n",
        "- Найдите книги, опубликованные после 2000 года, и отсортируйте их по цене."
      ],
      "metadata": {
        "id": "zsXQ_Pw-xdt7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import sum, max, min"
      ],
      "metadata": {
        "id": "6m4sYnZRyfvN"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grouped_df = df_join.groupBy(\"author_id\").agg(sum(\"price\").alias(\"sum_price\"))\n",
        "grouped_df = grouped_df.orderBy(col(\"sum_price\").desc()).limit(5)\n",
        "grouped_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1u__BDBkxhFc",
        "outputId": "5d327107-2cd4-4efa-f313-2043d5061703"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|author_id|         sum_price|\n",
            "+---------+------------------+\n",
            "|        2| 231.9700050354004|\n",
            "|        7|132.66000270843506|\n",
            "|        1| 111.8599967956543|\n",
            "|        8|107.15999984741211|\n",
            "|        5| 88.83000183105469|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_join.groupBy(\"genre\").count().orderBy(col(\"count\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZdjvcFWytdg",
        "outputId": "385331e9-18b8-4841-ecb6-7c1fe9fa0490"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-----+\n",
            "|      genre|count|\n",
            "+-----------+-----+\n",
            "|Non-Fiction|    9|\n",
            "|    Science|    3|\n",
            "|    Fiction|    3|\n",
            "|    Fantasy|    3|\n",
            "|    Mystery|    2|\n",
            "+-----------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_join.groupBy(\"author_id\").agg(avg(\"price\").alias(\"avg_price\")).orderBy(col(\"avg_price\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OJ7ETNazN5h",
        "outputId": "1b108ef1-85c2-4d44-9a0e-09ae3c57235e"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+\n",
            "|author_id|         avg_price|\n",
            "+---------+------------------+\n",
            "|        5| 88.83000183105469|\n",
            "|        4| 83.69999694824219|\n",
            "|        2|  57.9925012588501|\n",
            "|        9|46.310001373291016|\n",
            "|        7|44.220000902811684|\n",
            "|        6| 43.96500015258789|\n",
            "|        1| 37.28666559855143|\n",
            "|        8| 35.71999994913737|\n",
            "|       10|21.165000438690186|\n",
            "+---------+------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_join.where(col(\"publish_date\") >= \"2000-01-01\").orderBy(col(\"price\").desc()).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k22Z5qOLzvyW",
        "outputId": "c16815ea-ee4d-4b9e-849c-cad298731e14"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|author_id|book_id|  title|      genre|price|publish_date|     name|birth_date|  country|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "|        7|     20|Book_20|    Mystery|91.48|  2018-12-31| Author_7|1990-12-31|      USA|\n",
            "|        5|     19|Book_19|    Science|88.83|  2016-12-31| Author_5|1980-12-31|      USA|\n",
            "|        8|     15|Book_15|    Fantasy| 60.0|  2008-12-31| Author_8|1995-12-31|Australia|\n",
            "|        6|     17|Book_17|    Fantasy|47.57|  2012-12-31| Author_6|1985-12-31|      USA|\n",
            "|        1|     18|Book_18|Non-Fiction|43.92|  2014-12-31| Author_1|1960-12-31|    India|\n",
            "|        2|     16|Book_16|    Fiction|36.22|  2010-12-31| Author_2|1965-12-31|   Canada|\n",
            "|       10|     11|Book_11|Non-Fiction| 31.7|  2000-12-31|Author_10|2005-12-31|    India|\n",
            "|        8|     12|Book_12|Non-Fiction|31.02|  2002-12-31| Author_8|1995-12-31|Australia|\n",
            "|        1|     14|Book_14|    Fiction|26.84|  2006-12-31| Author_1|1960-12-31|    India|\n",
            "|        8|     13|Book_13|Non-Fiction|16.14|  2004-12-31| Author_8|1995-12-31|Australia|\n",
            "+---------+-------+-------+-----------+-----+------------+---------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.stop()"
      ],
      "metadata": {
        "id": "p-WCqh6a5wtu"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Самостоятельное задание  №3. Фильмы и актеры. С использованием временных таблиц и SQL\n"
      ],
      "metadata": {
        "id": "zfaBoA8A0NxS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        ".appName(\"Books\") \\\n",
        ".getOrCreate()\n",
        "\n",
        "movies_df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/movies.csv\", header=True)\n",
        "movie_actors_df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/movie_actors.csv\", header=True)\n",
        "actors_df = spark.read.csv(\"/content/drive/MyDrive/dataenj/pySpark_practice/actors.csv\", header=True)\n",
        "movies_df.show()\n",
        "movie_actors_df.show()\n",
        "actors_df.show()\n",
        "print(movies_df.dtypes)\n",
        "print(actors_df.dtypes)\n",
        "print(movie_actors_df.dtypes)\n",
        "\n",
        "movies_data_types = {\n",
        "    \"movie_id\": IntegerType(),\n",
        "    \"budget\": FloatType(),\n",
        "    \"release_date\": DateType()\n",
        "}\n",
        "\n",
        "movie_actors_data_types = {\n",
        "    \"movie_id\": IntegerType(),\n",
        "    \"actor_id\": IntegerType()\n",
        "}\n",
        "actors_data_types = {\n",
        "    \"actor_id\": IntegerType(),\n",
        "    \"birth_date\": DateType()\n",
        "}\n",
        "\n",
        "for column_name, data_type in movies_data_types.items():\n",
        "  movies_df = movies_df.withColumn(column_name, col(column_name).cast(data_type))\n",
        "for column_name, data_type in movie_actors_data_types.items():\n",
        "  movie_actors_df = movie_actors_df.withColumn(column_name, col(column_name).cast(data_type))\n",
        "for column_name, data_type in actors_data_types.items():\n",
        "  actors_df = actors_df.withColumn(column_name, col(column_name).cast(data_type))\n",
        "\n",
        "print(movies_df.dtypes)\n",
        "print(actors_df.dtypes)\n",
        "print(movie_actors_df.dtypes)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE7NscIE0DJF",
        "outputId": "47c2ca19-40fd-4ca8-f51e-5540b7a3000a"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------+------+------------+-----------+\n",
            "|movie_id|   title| genre|release_date|     budget|\n",
            "+--------+--------+------+------------+-----------+\n",
            "|       1| Movie_1|Horror|  2000-12-31|86600583.11|\n",
            "|       2| Movie_2|Comedy|  2001-12-31|12747400.83|\n",
            "|       3| Movie_3|Action|  2002-12-31| 18015774.7|\n",
            "|       4| Movie_4| Drama|  2003-12-31|48176120.61|\n",
            "|       5| Movie_5| Drama|  2004-12-31| 74050161.1|\n",
            "|       6| Movie_6|Action|  2005-12-31|14761218.31|\n",
            "|       7| Movie_7| Drama|  2006-12-31|44567036.43|\n",
            "|       8| Movie_8| Drama|  2007-12-31|48802276.17|\n",
            "|       9| Movie_9|Action|  2008-12-31|22016278.53|\n",
            "|      10|Movie_10|Action|  2009-12-31|12440279.29|\n",
            "|      11|Movie_11|Comedy|  2010-12-31|83805671.38|\n",
            "|      12|Movie_12|Comedy|  2011-12-31|50744099.33|\n",
            "|      13|Movie_13|Action|  2012-12-31| 2423742.36|\n",
            "|      14|Movie_14|Sci-Fi|  2013-12-31|80495148.83|\n",
            "|      15|Movie_15| Drama|  2014-12-31|98098586.74|\n",
            "|      16|Movie_16|Comedy|  2015-12-31|60986693.35|\n",
            "|      17|Movie_17| Drama|  2016-12-31|50867130.32|\n",
            "|      18|Movie_18|Horror|  2017-12-31|87963170.44|\n",
            "|      19|Movie_19|Action|  2018-12-31|95299162.18|\n",
            "|      20|Movie_20|Sci-Fi|  2019-12-31|75699154.67|\n",
            "+--------+--------+------+------------+-----------+\n",
            "\n",
            "+--------+--------+\n",
            "|movie_id|actor_id|\n",
            "+--------+--------+\n",
            "|       1|      25|\n",
            "|      16|       5|\n",
            "|       6|      16|\n",
            "|      16|      11|\n",
            "|      14|      21|\n",
            "|       3|       6|\n",
            "|      15|       9|\n",
            "|       3|      13|\n",
            "|       2|      24|\n",
            "|       1|       8|\n",
            "|       9|      14|\n",
            "|       9|      24|\n",
            "|       7|       1|\n",
            "|       3|      17|\n",
            "|      18|      24|\n",
            "|      11|       5|\n",
            "|       7|      25|\n",
            "|       9|       2|\n",
            "|       1|      25|\n",
            "|      14|      28|\n",
            "+--------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+--------+--------+----------+---------+\n",
            "|actor_id|    name|birth_date|  country|\n",
            "+--------+--------+----------+---------+\n",
            "|       1| Actor_1|1960-12-31|   Canada|\n",
            "|       2| Actor_2|1962-12-31|       UK|\n",
            "|       3| Actor_3|1964-12-31|       UK|\n",
            "|       4| Actor_4|1966-12-31|       UK|\n",
            "|       5| Actor_5|1968-12-31|    India|\n",
            "|       6| Actor_6|1970-12-31|      USA|\n",
            "|       7| Actor_7|1972-12-31|    India|\n",
            "|       8| Actor_8|1974-12-31|Australia|\n",
            "|       9| Actor_9|1976-12-31|      USA|\n",
            "|      10|Actor_10|1978-12-31|Australia|\n",
            "|      11|Actor_11|1980-12-31|      USA|\n",
            "|      12|Actor_12|1982-12-31|    India|\n",
            "|      13|Actor_13|1984-12-31|       UK|\n",
            "|      14|Actor_14|1986-12-31|   Canada|\n",
            "|      15|Actor_15|1988-12-31|       UK|\n",
            "|      16|Actor_16|1990-12-31|    India|\n",
            "|      17|Actor_17|1992-12-31|      USA|\n",
            "|      18|Actor_18|1994-12-31|       UK|\n",
            "|      19|Actor_19|1996-12-31|    India|\n",
            "|      20|Actor_20|1998-12-31|Australia|\n",
            "+--------+--------+----------+---------+\n",
            "only showing top 20 rows\n",
            "\n",
            "[('movie_id', 'string'), ('title', 'string'), ('genre', 'string'), ('release_date', 'string'), ('budget', 'string')]\n",
            "[('actor_id', 'string'), ('name', 'string'), ('birth_date', 'string'), ('country', 'string')]\n",
            "[('movie_id', 'string'), ('actor_id', 'string')]\n",
            "[('movie_id', 'int'), ('title', 'string'), ('genre', 'string'), ('release_date', 'date'), ('budget', 'float')]\n",
            "[('actor_id', 'int'), ('name', 'string'), ('birth_date', 'date'), ('country', 'string')]\n",
            "[('movie_id', 'int'), ('actor_id', 'int')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "movies_df.createOrReplaceTempView(\"movies\")\n",
        "movie_actors_df.createOrReplaceTempView(\"movie_actors\")\n",
        "actors_df.createOrReplaceTempView(\"actors\")"
      ],
      "metadata": {
        "id": "CVpXzIk646iF"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Найдите топ-5 жанров по количеству фильмов.\n",
        "- Найдите актера с наибольшим количеством фильмов.\n",
        "- Подсчитайте средний бюджет фильмов по жанрам.\n",
        "- Найдите фильмы, в которых снялось более одного актера из одной страны."
      ],
      "metadata": {
        "id": "_wn_olUC6Egv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_genres = spark.sql(\"\"\"\n",
        "SELECT m.genre, count(movie_id) AS total_films\n",
        "FROM movies m\n",
        "GROUP BY m.genre\n",
        "ORDER BY total_films DESC\n",
        "LIMIT 5;\n",
        "\"\"\")\n",
        "top_genres.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GKYXzbX15ugs",
        "outputId": "fb4f6d5a-b8db-417d-a737-f515fd5d4271"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----------+\n",
            "| genre|total_films|\n",
            "+------+-----------+\n",
            "| Drama|          6|\n",
            "|Action|          6|\n",
            "|Comedy|          4|\n",
            "|Horror|          2|\n",
            "|Sci-Fi|          2|\n",
            "+------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "top_actor = spark.sql(\"\"\"\n",
        "SELECT a.name, count(DISTINCT(ma.movie_id)) AS num_films\n",
        "FROM actors a\n",
        "INNER JOIN movie_actors ma\n",
        "ON ma.actor_id = a.actor_id\n",
        "GROUP BY a.name\n",
        "ORDER BY num_films DESC\n",
        "LIMIT 1;\n",
        "\n",
        "\"\"\")\n",
        "top_actor.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeFu8SFC7obU",
        "outputId": "d862c623-eceb-4942-df55-1895e951558d"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+\n",
            "|    name|num_films|\n",
            "+--------+---------+\n",
            "|Actor_24|        5|\n",
            "+--------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_budget = spark.sql(\"\"\"\n",
        "SELECT genre, avg(budget) AS avg_budget\n",
        "FROM movies m\n",
        "GROUP BY m.genre\n",
        "ORDER BY avg_budget DESC;\n",
        "\"\"\")\n",
        "avg_budget.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkuLCKHVCFiL",
        "outputId": "94190819-f873-4d05-e27b-e055aafcb4e7"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------------+\n",
            "| genre|    avg_budget|\n",
            "+------+--------------+\n",
            "|Horror|   8.7281876E7|\n",
            "|Sci-Fi|   7.8097152E7|\n",
            "| Drama|   6.0760218E7|\n",
            "|Comedy| 5.207096625E7|\n",
            "|Action|2.7492741875E7|\n",
            "+------+--------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_or_more_from_same_country = spark.sql(\"\"\"\n",
        "SELECT movie_id\n",
        "FROM movie_actors ma\n",
        "INNER JOIN actors a\n",
        "ON ma.actor_id = a.actor_id\n",
        "GROUP BY ma.movie_id\n",
        "HAVING count(DISTINCT(ma.actor_id)) > count(DISTINCT(a.country))\n",
        "\"\"\")## если различных актеров больше чем различных стран, значит 2 или больше из одной страны.\n",
        "two_or_more_from_same_country.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa-jYUJTDfKi",
        "outputId": "c1d00b6d-b04f-4390-b4b4-fc46357b084b"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|movie_id|\n",
            "+--------+\n",
            "|       1|\n",
            "|       3|\n",
            "|      15|\n",
            "|       7|\n",
            "|      10|\n",
            "|      18|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}