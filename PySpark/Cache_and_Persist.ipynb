{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUWT8VNRkP1Fp5+i4Oslsv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IlyaDenisov88/dataenj/blob/main/PySpark/Cache_and_Persist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLyF0-Zk4ITN",
        "outputId": "3fac18a4-59e2-45b4-b8f1-f46cb73706ae"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.3.tar.gz (317.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.3/317.3 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.3-py2.py3-none-any.whl size=317840625 sha256=c47ed504f891354a9a764ef624c7ff20db9a125ffc678bdf01c6e972e9ed305e\n",
            "  Stored in directory: /root/.cache/pip/wheels/1b/3a/92/28b93e2fbfdbb07509ca4d6f50c5e407f48dce4ddbda69a4ab\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cache"
      ],
      "metadata": {
        "id": "SpL1p_L8lu7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cache` — это метод в Apache Spark, который используется для кэширования данных в памяти. Он позволяет избежать повторного выполнения вычислений при повторном доступе к данным. Кэширование может существенно повысить производительность Spark-приложений, особенно если одни и те же данные используются многократно в различных этапах вычислений, то есть чаще всего при join операциях.\n",
        "\n",
        "Основная логика cache следующая -\n",
        "\n",
        "* Данные сохраняются в оперативной памяти всех рабочих узлов (executors) кластера.\n",
        "* При повторном доступе к данным Spark извлекает их из памяти, а не выполняет вычисления заново.\n",
        "* Метод `cache` помечает DataFrame или RDD для кэширования, но фактически кэширование происходит только при первом вызове действия (action), которое вызывает выполнение вычислений (например, `count`, `collect`, `show`).\n",
        "* Если данные не помещаются в память, Spark может использовать метод `persist` с соответствующим уровнем хранения (storage level), чтобы сохранить их на диск (но об этом попозже)\n"
      ],
      "metadata": {
        "id": "y4TpugmmlTzM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HUxVRkWRkxNB",
        "outputId": "d71e1a59-bdf1-4346-9bc3-251708c719ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|  name|\n",
            "+---+------+\n",
            "|  0|Name_0|\n",
            "|  2|Name_2|\n",
            "|  4|Name_4|\n",
            "|  6|Name_1|\n",
            "|  8|Name_3|\n",
            "| 10|Name_0|\n",
            "| 12|Name_2|\n",
            "| 14|Name_4|\n",
            "| 16|Name_1|\n",
            "| 18|Name_3|\n",
            "| 20|Name_0|\n",
            "| 22|Name_2|\n",
            "| 24|Name_4|\n",
            "| 26|Name_1|\n",
            "| 28|Name_3|\n",
            "| 30|Name_0|\n",
            "| 32|Name_2|\n",
            "| 34|Name_4|\n",
            "| 36|Name_1|\n",
            "| 38|Name_3|\n",
            "+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Cache Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(1000)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Применяем фильтр и кэшируем результат\n",
        "filtered_df = df.filter(col(\"id\") % 2 == 0).cache()\n",
        "\n",
        "# Первое действие (action) вызывает выполнение и кэширование\n",
        "filtered_df.count()  # Это действие выполнит фильтрацию и закэширует результат\n",
        "\n",
        "# Повторное использование закэшированных данных\n",
        "filtered_df.show()  # Это действие извлечет данные из кэша и отобразит их\n",
        "\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "У cache только один минус - метод `cache` использует стандартный уровень хранения `MEMORY_ONLY`. Поэтому двинемся в сторону persist. А далее рассмотрим и другие уровни хранения.\n",
        "\n"
      ],
      "metadata": {
        "id": "yZQbYGADllQm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Persist"
      ],
      "metadata": {
        "id": "gNoZzLGLlxS8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод `persist` в Apache Spark используется для сохранения RDD (Resilient Distributed Dataset) или DataFrame в памяти и/или на диске с различными уровнями хранения (storage levels). В отличие от `cache`, который использует только память для хранения данных, `persist` предоставляет более гибкие опции для управления кэшированием, включая использование дискового пространства и другие стратегии хранения.\n",
        "\n",
        "Рассмотрим основные задачи persist -\n",
        "\n",
        "1. `persist` позволяет выбирать различные уровни хранения, такие как память, диск или их комбинация, что помогает эффективно использовать доступные ресурсы кластера.\n",
        "\n",
        "2. Кэширование данных в памяти или на диске позволяет избежать повторного выполнения дорогостоящих вычислений при многократном доступе к данным, улучшая производительность приложений.\n",
        "\n",
        "3. Кэширование данных на диск может обеспечить дополнительную надежность, так как данные сохраняются и могут быть восстановлены в случае сбоя узла или других проблем.\n",
        "\n",
        "Теперь давайте рассмотрим основные уровни хранения, которые можно использовать с persist -\n",
        "\n",
        "* MEMORY_ONLY: Кэширует данные только в памяти. Если данные не помещаются, они не сохраняются на диск.\n",
        "* MEMORY_AND_DISK: Кэширует данные в памяти и на диске, если данные не помещаются в память.\n",
        "* DISK_ONLY: Кэширует данные только на диске.\n",
        "* MEMORY_ONLY_SER: Кэширует данные в памяти в сериализованном виде. Это уменьшает объем памяти, но увеличивает время доступа.\n",
        "* MEMORY_AND_DISK_SER: Кэширует данные в памяти и на диске в сериализованном виде.\n",
        "* OFF_HEAP: Кэширует данные в памяти вне кучи (off-heap), что может уменьшить накладные расходы на сборку мусора (Garbage Collection).\n",
        "\n",
        "Рассмотрим пример с Memory_And_Disk.\n",
        "\n"
      ],
      "metadata": {
        "id": "DEBG-pIglzJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import StorageLevel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Persist Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(1000)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Применяем фильтр и сохраняем результат с уровнем хранения MEMORY_AND_DISK\n",
        "filtered_df = df.filter(col(\"id\") % 2 == 0).persist(StorageLevel.MEMORY_AND_DISK)\n",
        "\n",
        "# Первое действие вызывает выполнение и кэширование\n",
        "filtered_df.count()  # Это действие выполнит фильтрацию и закэширует результат в памяти и на диске\n",
        "\n",
        "# Повторное использование закэшированных данных\n",
        "filtered_df.show()  # Это действие извлечет данные из кэша и отобразит их\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWxBkE-Zlw1m",
        "outputId": "fdb8b419-002f-47cd-8c19-7e8374374d6b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|  name|\n",
            "+---+------+\n",
            "|  0|Name_0|\n",
            "|  2|Name_2|\n",
            "|  4|Name_4|\n",
            "|  6|Name_1|\n",
            "|  8|Name_3|\n",
            "| 10|Name_0|\n",
            "| 12|Name_2|\n",
            "| 14|Name_4|\n",
            "| 16|Name_1|\n",
            "| 18|Name_3|\n",
            "| 20|Name_0|\n",
            "| 22|Name_2|\n",
            "| 24|Name_4|\n",
            "| 26|Name_1|\n",
            "| 28|Name_3|\n",
            "| 30|Name_0|\n",
            "| 32|Name_2|\n",
            "| 34|Name_4|\n",
            "| 36|Name_1|\n",
            "| 38|Name_3|\n",
            "+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "И также с disk_only.\n",
        "\n"
      ],
      "metadata": {
        "id": "YG39CvPf4Fzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import StorageLevel\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Persist Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(1000)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Применяем фильтр и сохраняем результат с уровнем хранения DISK_ONLY\n",
        "filtered_df = df.filter(col(\"id\") % 2 == 0).persist(StorageLevel.DISK_ONLY)\n",
        "\n",
        "\n",
        "filtered_df.count()  # Это действие выполнит фильтрацию и закэширует результат на диске\n",
        "\n",
        "\n",
        "filtered_df.show()  # Это действие извлечет данные из кэша и отобразит их\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAw-kPA14GQ4",
        "outputId": "ce2fb9ce-e57b-47dc-f673-c11f2d440dba"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+\n",
            "| id|  name|\n",
            "+---+------+\n",
            "|  0|Name_0|\n",
            "|  2|Name_2|\n",
            "|  4|Name_4|\n",
            "|  6|Name_1|\n",
            "|  8|Name_3|\n",
            "| 10|Name_0|\n",
            "| 12|Name_2|\n",
            "| 14|Name_4|\n",
            "| 16|Name_1|\n",
            "| 18|Name_3|\n",
            "| 20|Name_0|\n",
            "| 22|Name_2|\n",
            "| 24|Name_4|\n",
            "| 26|Name_1|\n",
            "| 28|Name_3|\n",
            "| 30|Name_0|\n",
            "| 32|Name_2|\n",
            "| 34|Name_4|\n",
            "| 36|Name_1|\n",
            "| 38|Name_3|\n",
            "+---+------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Также все работает. Но, возникает логичный вопрос - когда что необходимо использовать?\n",
        "\n",
        "Давайте разбираться.\n",
        "\n"
      ],
      "metadata": {
        "id": "X6I-lUUh4Qsm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEMORY_ONLY**\n",
        "\n",
        "**Описание**: Кэширует данные только в памяти. Если данные не помещаются в память, они не сохраняются на диск.\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда данные небольшие и могут поместиться в память всех узлов.\n",
        "- Когда нужно минимизировать время доступа к данным.\n",
        "- Когда допустимо потерять кэшированные данные в случае нехватки памяти.\n"
      ],
      "metadata": {
        "id": "AzzSafgs4Rhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEMORY_AND_DISK**\n",
        "\n",
        "**Описание**: Кэширует данные в памяти и на диске, если данные не помещаются в память.\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда данные слишком большие для хранения только в памяти.\n",
        "- Когда важно сохранить данные, даже если они не помещаются в память.\n",
        "- Когда допустимо более медленное время доступа к данным, сохраненным на диск.\n"
      ],
      "metadata": {
        "id": "bDHYHhz24i7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISK_ONLY**\n",
        "\n",
        "**Описание**: Кэширует данные только на диске.\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда данные слишком большие для хранения в памяти.\n",
        "- Когда приоритетом является сохранение данных, а не скорость доступа к ним.\n",
        "- Когда узлы имеют ограниченную память, но достаточно места на диске.\n"
      ],
      "metadata": {
        "id": "JeeekOD64qcC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEMORY_ONLY_SER**\n",
        "\n",
        "**Описание**: Кэширует данные в памяти в сериализованном виде, что уменьшает объем памяти, но увеличивает время доступа.\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда данные слишком большие для хранения в несериализованном виде.\n",
        "- Когда доступная память ограничена.\n",
        "- Когда допустимо большее время доступа из-за необходимости десериализации данных.\n"
      ],
      "metadata": {
        "id": "GgxeeYbB4yZp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEMORY_AND_DISK_SER**\n",
        "\n",
        "**Описание**: Кэширует данные в памяти и на диске в сериализованном виде.\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда данные слишком большие для хранения в памяти в несериализованном виде.\n",
        "- Когда важно сохранить данные и доступна ограниченная память.\n",
        "- Когда допустимо большее время доступа из-за необходимости десериализации данных.\n"
      ],
      "metadata": {
        "id": "3_pNpUSa48gd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**OFF_HEAP**\n",
        "\n",
        "**Описание**: Кэширует данные в памяти вне кучи (off-heap), что может уменьшить накладные расходы на сборку мусора (Garbage Collection).\n",
        "\n",
        "**Когда использовать**:\n",
        "- Когда необходимо минимизировать влияние сборки мусора на производительность.\n",
        "- Когда приложение требует стабильной и предсказуемой производительности.\n",
        "- Когда доступна поддержка off-heap памяти.\n"
      ],
      "metadata": {
        "id": "y-Vd2Qqe5EX-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Такая небольшая подсказка получилась. Но это если научным языком объяснять. Поэтому давайте также опишем когда что применять, исходя из практического опыта.\n",
        "\n",
        "**Для небольших данных:**\n",
        "\n",
        "- Используйте MEMORY_ONLY для минимизации времени доступа, если данные полностью помещаются в память.\n",
        "\n",
        "**Для больших данных:**\n",
        "- Используйте MEMORY_AND_DISK, если данные не помещаются в память и важно сохранить данные.\n",
        "- Используйте DISK_ONLY, если память ограничена и приоритетом является сохранение данных.\n",
        "\n",
        "**Для ограниченной памяти:**\n",
        "- Используйте MEMORY_ONLY_SER или MEMORY_AND_DISK_SER, если данные слишком большие для хранения в несериализованном виде.\n",
        "\n",
        "**Для стабильной производительности:**\n",
        "- Используйте OFF_HEAP, если необходимо минимизировать влияние сборки мусора.\n",
        "\n",
        "**Для критически важных данных:**\n",
        "- Рассмотрите использование MEMORY_AND_DISK или DISK_ONLY для обеспечения сохранности данных даже в случае нехватки памяти.\n"
      ],
      "metadata": {
        "id": "lOOGHsgr5RNs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Цитата ответа Артема на фопрос о различиях `cache` и `persist`:\n",
        "*я не помню точно, но по моему сначала появился cache, потом persist. Как спарк контекст и спарк сессия. А отличия у них нету. В cache не указывается уровень, а в persist указывается.*\n",
        "\n"
      ],
      "metadata": {
        "id": "KU7tZlfT8n4-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "rdd.cache()\n",
        "\n",
        "rdd = sc.parallelize([1, 2, 3, 4, 5])\n",
        "rdd.persist(StorageLevel.MEMORY_ONLY)\n",
        "\n",
        "# Останавливаем SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "9GnRd4bs78bE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unpersist"
      ],
      "metadata": {
        "id": "zJIb7RsZ9BLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Метод `unpersist` в Apache Spark используется для удаления ранее закэшированных данных из памяти и/или диска. Он отменяет кэширование, освобождая ресурсы, занятые этими данными. Это особенно полезно для управления памятью и ресурсами кластера, когда больше нет необходимости в закэшированных данных."
      ],
      "metadata": {
        "id": "anVEN9R_9RkW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задачи, но все же я их распишу.\n",
        "\n",
        "1. Метод `unpersist` освобождает память и/или диск, занятые закэшированными данными. Это позволяет Spark использовать освободившиеся ресурсы для других задач.\n",
        "\n",
        "2. Метод `unpersist` может быть применен как к RDD, так и к DataFrame, которые были ранее закэшированы с использованием методов `cache` или `persist`.\n",
        "\n",
        "3. По умолчанию, `unpersist` выполняет ленивую очистку, то есть данные удаляются только тогда, когда Spark решает, что это необходимо. Однако можно принудительно удалить данные немедленно. Это очень важно знать.\n",
        "\n",
        "Ну и в заключение пример.\n",
        "\n"
      ],
      "metadata": {
        "id": "ACmM8Lob9dB9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Unpersist Example\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "\n",
        "data = [(i, f\"Name_{i % 5}\") for i in range(1000)]\n",
        "df = spark.createDataFrame(data, [\"id\", \"name\"])\n",
        "\n",
        "# Применяем фильтр и кэшируем результат\n",
        "filtered_df = df.filter(col(\"id\") % 2 == 0).cache()\n",
        "\n",
        "# Выполняем действие, чтобы закэшировать данные\n",
        "filtered_df.count()\n",
        "\n",
        "# Освобождаем закэшированные данные\n",
        "filtered_df.unpersist()\n",
        "\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "id": "WZLwTVdW9O-e"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Практика"
      ],
      "metadata": {
        "id": "P34M6DD6-Bg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CacheAndPersist\").getOrCreate()\n",
        "\n",
        "data = [(i, i*2) for i in range(1, 100000)] # список\n",
        "df = spark.createDataFrame(data, [\"num\", \"double\"]) # df из списка\n",
        "\n",
        "# функция для сравнения времени кеширования при использовании cache() и persist()\n",
        "def measure_time(action, rdd_or_df): # операция и данные\n",
        "  start_time = time.time()\n",
        "  rdd_or_df.count() # действие к датафрейму (чтобы кеширование сделалось)\n",
        "  print(f\"Время выполнения для {action}: {time.time() - start_time:.4f} секунд\")\n",
        "\n",
        "# Архивация данных, чтобы потом быстро получать к ним доступ\n",
        "df_cached = df.cache()\n",
        "measure_time(\"cache\", df_cached)\n",
        "\n",
        "df_cached.unpersist() # очистить  оперативную память от кеша\n",
        "\n",
        "df_persisted = df.persist() # по умолчинию MEMORY_AND_DISK\n",
        "measure_time(\"persist\", df_persisted)\n",
        "\n",
        "df_persisted.unpersist()\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yGpcdB01-BNK",
        "outputId": "1273820a-19fe-4c61-87b2-dad9f01abadf"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения для cache: 1.5944 секунд\n",
            "Время выполнения для persist: 1.0087 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- в данном случае persist по времени быстрее\n",
        "- на самом деле, чем больше данных, тем больше выигрывает cache (тк он не работает с диском).\n"
      ],
      "metadata": {
        "id": "XHaCidmMQpjs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# cache - только оперативная память\n",
        "# persist - оперативная память + диск"
      ],
      "metadata": {
        "id": "IRofpmRwRFB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Что когда использовать на практике"
      ],
      "metadata": {
        "id": "bxxRtqyKSLRJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Когда данные не помещаются в ОП - persist\n",
        "- Когда помещаются - использовать cache\n",
        "- Вместе - при сложных join в persist - результаты и большие таблицы, в cache - маленькие таблицы"
      ],
      "metadata": {
        "id": "uASdbyBxRogy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Дз: что быстрее при чтении Cache или Persist"
      ],
      "metadata": {
        "id": "jCYSHOLHQne3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сработает ли также хорошо persist на чтение?"
      ],
      "metadata": {
        "id": "oEKwMW9JRi7a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CacheAndPersist\").getOrCreate()\n",
        "\n",
        "data = [(i, i*2) for i in range(1, 10000000)] # список\n",
        "df = spark.createDataFrame(data, [\"num\", \"double\"]) # df из списка\n",
        "\n",
        "# функция для сравнения времени кеширования при использовании cache() и persist()\n",
        "def measure_100times_read_time(action, rdd_or_df): # операция и данные\n",
        "  rdd_or_df.count() # действие, чтобы кеширование не учитывалось во время чтения\n",
        "  read_start_time = time.time()\n",
        "  for i in range(100):\n",
        "    rdd_or_df.show()  # Это действие извлечет данные из кэша и отобразит их\n",
        "  print(f\"Время выполнения для {action}: {time.time() - read_start_time:.4f} секунд\")\n",
        "\n",
        "# Архивация данных, чтобы потом быстро получать к ним доступ\n",
        "df_cached = df.cache()\n",
        "measure_time(\"cache\", df_cached)\n",
        "\n",
        "df_cached.unpersist() # очистить  оперативную память от кеша\n",
        "\n",
        "df_persisted = df.persist() # по умолчинию MEMORY_AND_DISK\n",
        "measure_time(\"persist\", df_persisted)\n",
        "\n",
        "df_persisted.unpersist()\n",
        "\n",
        "spark.stop()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlMYm7PFSP_t",
        "outputId": "294d9794-5625-4ea5-e5f4-db80ed9c2fef"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Время выполнения для cache: 21.7299 секунд\n",
            "Время выполнения для persist: 21.1507 секунд\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видим, что для многократного чтения результат сопоставим\n",
        "\n",
        "Если сравнить чисто время чтения данных без выполнения кеширования на удивление быстрее работает persist"
      ],
      "metadata": {
        "id": "ICxI0Nu6UF5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Проверка использования оперативки и диска\n",
        "import psutil\n",
        "\n",
        "# Получение общей информации о памяти\n",
        "mem = psutil.virtual_memory()\n",
        "print(f\"Общая память: {mem.total / (1024 * 1024):.2f} MB\")\n",
        "print(f\"Используется: {mem.used / (1024 * 1024):.2f} MB\")\n",
        "print(f\"Свободно: {mem.available / (1024 * 1024):.2f} MB\")\n",
        "print(f\"Процент использования: {mem.percent}%\")\n",
        "\n",
        "# Получение информации о диске\n",
        "disk = psutil.disk_usage('/')\n",
        "print(f\"Общий объем диска: {disk.total / (1024 * 1024 * 1024):.2f} GB\")\n",
        "print(f\"Используется: {disk.used / (1024 * 1024 * 1024):.2f} GB\")\n",
        "print(f\"Свободно: {disk.free / (1024 * 1024 * 1024):.2f} GB\")\n",
        "print(f\"Процент использования: {disk.percent}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrisPJmuVCuS",
        "outputId": "a7fd6be5-8fa5-4b6f-8ae0-c84b311bce0d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Общая память: 12978.96 MB\n",
            "Используется: 3386.64 MB\n",
            "Свободно: 9270.00 MB\n",
            "Процент использования: 28.6%\n",
            "Общий объем диска: 107.72 GB\n",
            "Используется: 37.35 GB\n",
            "Свободно: 70.35 GB\n",
            "Процент использования: 34.7%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "(выше отобразились характеристики гугловской машины)"
      ],
      "metadata": {
        "id": "lxQoFNAQWzPP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "E9zIkjAYWgIw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ну да, нагрузка на оперативу немаленькая..."
      ],
      "metadata": {
        "id": "I8TzHSf2WhfX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "В общем в теории cache быстрее на чтение, persist - хорошо, когда мало оперативы и нужно че-то подсохранить на диск"
      ],
      "metadata": {
        "id": "8mtmVzDuXS6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестовые вопросы"
      ],
      "metadata": {
        "id": "qrpvHIpnYThH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Что произойдет, если вы вызовете cache() на DataFrame, который уже закэширован с использованием persist(StorageLevel.DISK_ONLY)?\n",
        "\n",
        "- **Ответ**: DataFrame останется закэшированным на диске, так как persist имеет приоритет над cache."
      ],
      "metadata": {
        "id": "ZmGiFh6pYWjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Какой уровень хранения следует использовать, если необходимо кэшировать данные для минимизации влияния сборки мусора на производительность?\n",
        "- OFF_HEAP\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IwK3hkRoYXmw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Какое поведение ожидается при вызове unpersist() на DataFrame, который был закэширован с использованием persist(StorageLevel.MEMORY_AND_DISK)?\n",
        "\n",
        "- Данные будут удалены из памяти и с диска.\n"
      ],
      "metadata": {
        "id": "wz8V8_9OYmWy"
      }
    }
  ]
}